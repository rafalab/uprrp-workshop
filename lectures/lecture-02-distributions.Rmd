---
title: "Distributions"
author: "Rafael A. Irizarry"
date: "17-2-8"
output:
  ioslides_presentation:
    fig_caption: no
    fig_height: 6
    fig_width: 7
  beamer_presentation: default
  slidy_presentation: default
---

```{r setup, include=FALSE}
library(tidyverse)
library(dslabs)
ds_theme_set()
options(digits = 3)
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)
```

## Distributions Introduction (Video 1)
 
- You may have noticed that numerical data is often summarized with the _average_ value. 
- For example, the quality of a high school is sometimes summarized with one number: the average score in a standardized test. 
- Occasionally a second number is reported: the _SD_. 
- So, for example, you might read a report stating that scores were 680 plus or minus 50 (the SD). 
- Note that the report has summarized an entire vector of scores with with just two numbers. 
- Is this appropriate? 
- Is there any important piece of information we are missing by only looking at this summary rather than the entire list? 

## Learning objective

- It turns out that, in some cases, these two numbers are pretty much all we need to understand the data.  
- data visualization techniques  will help us determine when this two number summary is appropriate. 
- These same techniques will serve as an alternative for when these two numbers are not enough.

## Summarizing lists of numbers 

- Our first data visualization building block is learning to summarize lists of factors or numeric vectors.
- The most basic statistical summary of a list of objects or numbers is it's distribution. 
- Once a vector has been summarized as a distribution, there are several data visualization techniques to effectively relay this information.

## Data types (Video 2)

- An important first step in deciding how to visualize data is to know what type of data
- We will be working with two type of variables: categorical and numeric. 
- Each can be divided into two other groups: categorical can be ordinal or not 
- numerical variables can be discrete or continuous.


## Categorical 

- Variables that are defined by a small number of groups we call _categorical data_.
- Two simple examples are sex (male or female), regions (Northeast, South, North Central, West). 
- Some categorical data can be ordered, for example spiciness (mild, medium, hot), even if they are not numbers per-se. 
- In statistics text books they sometimes refer to these as _ordinal_ data. 

## Numerical 

- Example of numerical data are population sizes, murder rates, and heights. 
- We can further divide numerical data into continuous and discrete. 
- Continuous variables are those that can take any value, such as heights if measured with enough precision. 
- For example a pair of twins may be 68.12 and 68.11 inches receptively.
- Counts, such as population sizes, are discrete because they have to be round numbers.

## Numericals as ordinal

- Note that discrete numeric data can be considered ordinal. An example are heights rounded to nearest inch
- Although this is technically true,  we usually reserve the term ordinal data for variables belonging to a small number of different groups, with each group having many members. 
-  In contrast, when we have many groups with few cases in each group we typically refer as discrete numerical variable. 
- So, for example, the number of packs of cigarettes, a person smokes a day rounded to the closes pack, would be considered original while the actual number of cigarettes would be considered a numerical variable. 
- But indeed, there examples that can be considered both when it comes to visualizing data.


## Motivation

- Here we introduce a new motivating problem.
- It is an artificial one, but it will help us illustrate the concepts needed to understand distributions. 
- Pretend that we have to describe the heights of our classmates to ET, an extraterrestrial that has never seen humans. 

## The Data 

- As a first step we need to collect data. 
- To do this we ask students to report their heights in inches. 
- We ask them to provide sex information because we know there are two different groups of heights: male and female 
- We collect the data and save it in a data frame:


```{r load-heights, warning=FALSE, message=FALSE}
library(dslabs)
data(heights)
head(heights)
```

## First options

- One way to convey the heights to ET is to simply send him this list of `r nrow(heights)` heights. 
- But there are much more effective ways to convey this information and understanding the concept of a distribution will help. 
- To simplify the explanation, at first we focus on male heights. 


## Distribution Function

- The most basic statistical summary of a list of objects or numbers is it's distribution. 
- The simplest way to think of a distribution is as a compact description of a list with many entries. 
- This concept should not be new for most of you. 
- For example, with categorical data, the distribution simply describes the proportion of each unique category. 

## Distribution Function for binary daa

- For example the sex represented in the heights data set is:

```{r farm-animals, echo = FALSE}
prop.table(table(heights$sex))
```

- This two category _frequency table_ is the simplest form of a distribution we can form.
- We don't really need to visualize it since one number describes everything we need to know __`r round(100*mean(heights$sex=="Female"))`__% are females and the rest are males. 

## Distribution Function: categorical data

- When there are more categories then a simple barplot describes the distribution. Here is an example with the US state regions:

```{r, echo=FALSE}
murders %>% ggplot(aes(x=region, fill=region)) + 
  geom_bar(aes(y = (..count..)/sum(..count..))) + 
  ylab("proportions")
```

## Distribution Function: categorical data

- Although, this particular plot, a graphical representation of a frequency table, does not provide much more insight than a table itself, it is a first a example of how we convert a vector into a visualizing that succinct summarizes all the information in the vector. 
- When  the data is numerical, the task is more challenging.  

## Cumulative Distribution Functions


- In general, when data is not categorical, reporting the frequency of each unique entry is not an effective summary since most entries are unique. 
- For example, while several students reported a height of 68 inches, only one student reported a height of

`68.503937007874` inches 

- and  only one student reported a height 

`68.8976377952756` inches. 

- We assume that they converted from 174 and 175 centimeters respectively.

## Cumulative Distribution Functions ctd

- Statistics text books teach us that a more useful way to define a distribution for numeric data is to define a function that reports the proportion of the data below $a$ for all possible values of $a$. 
- This function is called the cumulative distribution function (CDF). 
- In Statistics the following notation is used:

$$ F(a) = \mbox{Pr}(x \leq a) $$


## Cumulative Distribution Functions ctd

- Here is a plot of $F$ for the height data:

```{r ecdf,fig.cap="Empirical cummulative distribution function for male  height.", echo=FALSE}
heights %>% filter(sex=="Male") %>% ggplot(aes(height)) + 
  stat_ecdf() +
  ylab("F(a)") + xlab("a")
```

## Cumulative Distribution Functions ctd

- Like the frequency table does for categorical data, the CDF defines the distribution for numerical data. 
- From the plot we can see, for example, that `r round(ecdf(heights$height[heights$sex=="Male"])(66)*100)`% 
of the values are below 66, since $F(66)=$ `r ecdf(heights$height[heights$sex=="Male"])(66)`, or that `r round(ecdf(heights$height[heights$sex=="Male"])(72)*100)`% of the values are below 72, since $F(72)=$ `r ecdf(heights$height[heights$sex=="Male"])(72)`, 
etc... 
- In fact, we can report the proportion of values between any two heights, say $a$ and $b$ by computing $F(b) - F(a)$. 
- This means that if we send this plot above to ET, he will have all the information needed to reconstruct the entire list.

## Final note

A final note: because CDFs can be defined mathematically, as opposed to using data as we do here, the word _empirical_ is added to distinguish and we use the term empirical CDF (ECDF) instead. 


## Histograms (new video)

- Although the CDF concept is widely discussed in statistics textbooks, the plot is actually not very popular in practice. 
- The main reason is that it does not easily convey characteristics of interest such as: 
- at what value is the distribution centered?
- Is the distribution symmetric? 
- What ranges contain 95% of the values? 

## Histograms continued

-  Histograms are much preferred because it greatly facilitates answering such questions.
- Histograms sacrifice just a bit of information to produce plots that are much easier to interpret. 

## Histograms defined
- The simplest way to make a histograms is to divide the span of our data into non-overlapping bins of the same size.
- Then for each bin we count the number of values that fall in that interval.
- The histogram plots these counts as bars with the base of the bar the interval. 

## Height histogram

- Here is the histogram for the height data spiting the range of values into one inch intervals $[53.5,54.5],(55.5,56.5],...,(80.5,81.5]$
  
```{r height-histogram, echo=FALSE}
heights %>% filter(sex=="Male") %>% ggplot(aes(height)) + geom_histogram(binwidth = 1)
```

## Histogram as summary
- If we send this plot to ET, he will immediately learn some important properties about our data. 
- First, the range of the data is from 55 to 81 with the majority (more than 95%) between 63 and 75 inches. 
- Second, the heights are close to symmetric around 69 inches. 
- Also note that by adding up counts, ET could obtains very good approximation of the proportion of the data in any interval. 
-  provides almost all the information contained in the raw list of `r sum(heights$sex=="Male")` heights with just 23 bin counts.

## Information lost

- So what information do we lose? 
- Note that all values in each interval are treated the same when computing bin heights.
- So, for a example, the histogram does not distinguish between  64, 64.1, and 64.2 inches. 
- Given that these differences are almost unnoticeable to the eye, the practical implications are negligible.


## Smoothed Density 

- Smooth density plots are aesthetically more appealing than histograms. 
- Here is what a smooth density plot looks like for our heights data:

```{r example-of-smoothed-density, echo=FALSE}
heights %>% 
  filter(sex=="Male") %>% 
  ggplot(aes(height)) + 
  geom_density(alpha=.2, fill= "#00BFC4")  
```

## Smoothed Density ctnd

- Note that we no longer have sharp edges at the interval boundaries and that many of the local peaks have been removed. - Also, notice that the scale of the y-axis changed from counts to _density_.


```{r example-of-smoothed-density-2, echo=FALSE}
heights %>% 
  filter(sex=="Male") %>% 
  ggplot(aes(height)) + 
  geom_density(alpha=.2, fill= "#00BFC4")  
```

## How are Smoothed Densities created?

- To understand the smooth densities we have to understands _estimates_ a topic we don't cover until a later chapter. 
- However, we provide a heuristic explanation to help you understand the basics and you can use this useful data visualization tool.

## How are Density created? ctnd

- The main new concept you have to understand is that we assume that our list of observed values comes from a much much larger list of unobserved values. 
- So in the case of heights, you can imagine our list of `r nrow(heights)` students comes from a hypothetical list containing all the heights of all the students in all the world measured very precisely. 
- Let's say there are 1,000,000 of these. This list of values, like any list of values, has a distribution and this is really what we want to report to ET since it is much general.
- Unfortunately we don't get to see it. 

## How are densities created? ctnd

- However, we make an assumption that helps us perhaps approximate it. 
- Because we have 1,000,000 values, measured very precisely, we can make a histogram with very very small bins. 
- The assumption is that if we do this, consecutive bins will be similar, this is what we mean by smooth: we don't have big jumps. 

## How are densities created? ctnd

- Here a hypothetical histogram with bins of size 1

```{r simulated-data-histogram-1, echo=FALSE}
x <- data.frame(height = c(rnorm(1000000,69,3), rnorm(1000000,65,3)))
x %>% ggplot(aes(height)) + geom_histogram(binwidth = 1)
```


## How are densities created? ctnd

- The smaller we make the bins the smoother the histogram gets. 

```{r simulated-data-histogram-2, echo=FALSE, message=FALSE}
p1 <- x %>% ggplot(aes(height)) + geom_histogram(binwidth = 1) + ggtitle("binwidth=1")
p2 <- x %>% ggplot(aes(height)) + geom_histogram(binwidth = 0.5) + ggtitle("binwidth=0.5") 
p3 <- x %>% ggplot(aes(height)) + geom_histogram(binwidth = 0.1) + ggtitle("binwidth=0.1")
library(gridExtra)
grid.arrange(p1, p2, p3, nrow = 1)
```

## How are densities created? ctnd

- The smooth density is basically the curve that goes through the top of the histogram bars when the bins are very very small. 

```{r, echo=FALSE}
x %>% ggplot(aes(height)) + 
  geom_histogram(aes(y=..density..), binwidth = 0.1) +
  geom_density(col="#00BFC4")
```

- To make the curve not depend on the hypothetical size of the hypothetical list we compute the curve on frequencies rather than counts

## How are densities created? ctnd

```{r smooth-density, echo=FALSE}
hist1 <- heights %>% 
  filter(sex=="Male") %>% 
  ggplot(aes(height)) +
  geom_histogram(aes(y=..density..), binwidth = 1) 
hist2 <- hist1 +
  geom_density(col="#00BFC4")
hist3 <- hist1 + 
  geom_point(data = ggplot_build(hist2)$data[[1]], aes(x,y))
hist4 <- ggplot() + geom_point(data = ggplot_build(hist2)$data[[1]], aes(x,y)) + xlab("height") + ylab("density")
hist5 <- hist4 + geom_line(data = ggplot_build(hist2)$data[[2]], aes(x,y),col="#00BFC4")
hist6 <- heights %>% 
  filter(sex=="Male") %>% 
  ggplot(aes(height)) +
  geom_density(alpha = 0.2, fill="#00BFC4")
``` 


- Now, back to reality. 
- We don't have millions of measurements, instead we have `r sum(heights$sex=="Male")` and we can't make a histogram with very small bins. 
- Instead we make the histogram, computing frequencies rather than counts, using bin sizes appropriate for our data.

## How are densities created? ctnd

- Because it is small sample we get unsmooth variation in these heights. 

```{r, echo=FALSE}
hist1
```

## How are densities created? ctnd

- To smooth the histogram, we keep the heights

```{r, echo=FALSE}
hist3
```

## How are densities created? ctnd


```{r, echo=FALSE}
hist4
```

## How are densities created? ctnd

- we draw a smooth curve that goes through the tops of the histogram bars:

```{r, echo=FALSE}
hist5
```

## How are densities created? ctnd

- We keep this curve
```{r, echo=FALSE}
hist2
```

## How are densities created? ctnd

- And use it to define the density
```{r, echo=FALSE}
hist6
```

## How smooth?

- Note that _smooth_ is a relative term. 
- We can actually control how _smoothness_ of the curve that defines the smooth density through an option in the function that computes the smooth density. 

## How smooth? ctnd

- Here are two examples using different degrees of smoothness on the same histogram:


```{r, echo=FALSE}
p1 <- heights %>% filter(sex=="Male")%>% ggplot(aes(height)) +
  geom_histogram(aes(y=..density..), binwidth = 1) + 
  geom_density(col="#00BFC4", adjust = 0.5)
p2 <- heights %>% filter(sex=="Male") %>% ggplot(aes(height)) +
  geom_histogram(aes(y=..density..), binwidth = 1) + 
  geom_density(col="#00BFC4", adjust = 2)
grid.arrange(p1,p2, ncol=2)
```

## How smooth? ctnd

- We need to make this choice with care as the resulting visualizations can change our interpretation of the data. 
- We should select a degree of smoothness that we can defend as being representative of the underlying data. 
- In the case of height, we really do have reason to believe that there should the proportion of people with similar heights should be the same. 

## How smooth? ctnd

- For example, the proportion that is 72 inches should be more similar to the proportion that is 71, then to the proportion that is 78 or 65. 
- This implies that the curve should be pretty smooth; more like the example on the right than on the left.

- While the histogram is an assumption free summary, the smoothed density is based on assumptions. 


## Interpreting the y-axis

- Finally, we point out that interpreting the y-axis of a smooth density plot is not straight forward. 
- It is scaled so that the area under the density curve adds up to 1. 
- So if you imagine we form a bin with a base 1 unit in length, the y-axis value tells us the proportion of values in that bin. But this is only true for bins of size 1. 
- For other sized intervals, the best way to determine the proportion of data in that interval is by computing the proportion of the total area contained in that interval. 


## Interpreting the y-axis ctnd

- For example here are the proportion of values between 65 and 68:

```{r area-under-curve, echo=FALSE}
d <- with(heights, density(height[sex=="Male"]))
tmp <- data.frame(height=d$x, density=d$y)
tmp %>% ggplot(aes(height,density)) + geom_line() + 
  geom_area(aes(x=height,y=density), data = filter(tmp, between(height, 65, 68)), alpha=0.2, fill="#00BFC4")
```

- The proportion of this area is about `r round(mean(between(heights$height, 65, 68)),2)` meaning that about that proportion is between 65 and 68 inches.

## Summary with a density plot

- Understanding this we are ready to use the smooth density as a summary. 
- For this dataset we would feel quite comfortable with the smoothness assumption and 

## Summary with a density plot ctnd

- therefore with sharing this aesthetically pleasing figure with ET, which he could use to understand our male heights data:

```{r example-of-smoothed-density-3, echo=FALSE}
heights %>% 
  filter(sex=="Male") %>% 
  ggplot(aes(height)) + 
  geom_density(alpha=.2, fill= "#00BFC4")  
```


## Densities Permit Stratification

- As a final note, we point out that an advantage of smooth densities over histograms for visualization purposes is that makes it easier to compare two distributions. 
- This in large part because the jagged edges of the histogram add clutter. Here is an example comparing male and female heights:

## Densities Permit Stratification ctnd

```{r, echo=FALSE}
heights %>% ggplot(aes(height, fill=sex)) + geom_density(alpha = 0.2)
```

- With the right argument, `ggplot` automatically shades the intersecting region with a different color.


## Normal Distribution (new video)

- Histograms and density plots provide excellent summaries of a distribution. 
- But can we summarize even further?
- We often see the average and standard deviation used as summary statistics: a two number summary! 
- To understand what these summaries are and why they are so widely used we need to understand the normal distribution. 

## Normal Distribution ctnd

- The normal distribution, also known as the bell curve and as the Gaussian distributions, is one of the most famous mathematical concepts in history. 
- A reason for this is that approximately normal distributions occur in many situations. 
- Examples include gambling winnings, heights, weights, blood pressure, standardized test scores, and experimental measurement errors. 
- There are explanations for this, but we explain this in a later chapter.
- Here we focus on how the normal distribution helps us summarize data. 

## Normal Distribution ctnd

- Rather than using data, the normal distribution is defined with a mathematical formula. 
- For any interval $(a,b)$ the proportion of values in that interval can be computed using this formula:

$$\mbox{Pr}(a < x < b) = \int_a^b \frac{1}{\sqrt{2\pi}s} \exp\left\{-\frac{1}{2}\left( \frac{x-m}{s} \right)^2\right\} \, dx$$

## Normal Distribution ctnd

- You don't need to memorize or understand the details of the formula. 
- But note that it is completely defined by just two parameters $m$ and $s$, the rest of the symbols in the formula represent  the interval ends that we determine, $a$ and $b$, and known mathematical constants $\pi$ and $\mathrm{e}$.
- These two, parameters $m$ and $s$ are referred to as the _average_, also called the _mean_, and the _standard deviation_ (SD) of the distribution respectively. 

## Normal Distribution ctnd

- The distribution is symmetric, centered at the average, and most values (about 95%) are withing 2 SDs from the average. 
- Here is what it looks like when the average is 0 and the SD is 1:
```{r normal-distribution-density, echo=FALSE}
mu <- 0; s <- 1
norm_dist <- data.frame(x=seq(-4,4,len=50)*s+mu) %>% mutate(density=dnorm(x,mu,s))
norm_dist %>% ggplot(aes(x,density)) + geom_line()
```

## Normal Distribution ctnd

- The fact that the distribution is defined by just two parameters implies that if a dataset is approximated by a normal distribution, all the information needed to describe the distribution can be encoded in just two numbers: the average and the standard deviation, which we now define for an arbitrary list of numbers.

## Average and SD

- For a list of numbers contained in a vector `x` the average is defined as 

```{r, eval=TRUE}
average <- sum(x) / length(x)
```

- and the SD is defined as
```{r}
SD <- sqrt( sum( (x-mu)^2) / length(x))
```

- which can be interpreted as the average distance between values and their average. 

## Average and SD ctnd

- Let's compute the values for the height for males which we will store in the object $x$:

```{r}
index <- heights$sex=="Male"
x <- heights$height[index]
```

## Average and SD ctnd

- The pre-built functions `mean` and `sd` [Footnote: SD divide by n-1] can be used here:
```{r}
average <- mean(x)
SD <- sd(x)
c(average=average,SD=SD)
```

## Average and SD ctnd

- Here is a plot of the smooth density and the normal distribution with mean average = `r average` and SD = `r SD`

```{r, echo=FALSE}
norm_dist <- data.frame(x=seq(-4,4,len=50)*SD+average) %>% mutate(density=dnorm(x,average,SD))
heights %>% filter(sex=="Male") %>% ggplot(aes(height)) +
  geom_density(fill="#0099FF") +
  geom_line(aes(x, density),  data = norm_dist, lwd=1.5) 
```

## Average and SD ctnd

- We note that the it does appear to be quite a good approximation. 
- We now will see how well this approximation works at predicting proportion of values within intervals.

## Standardized units

- For data that is approximately normally distributed it is convenient to think in term of _standard units_.  
- The standard unit of a value tells us how many standard deviations away from the average it is. 
- Specifically, for a value $x$ we define it as $z = (x-\mbox{average})/\mbox{SD}$. 

## Standardized units

- If you look back at the formula for the normal distribution you notice that what is being exponentiation is $- z^2$. 
- The maximum of of $\exp{\{-z^2/2\}}$ is when $z=0$ which explains why the maximum of the distribution is at the mean.
- It also explains the symmetry since $-z^2$ is symmetric around 0.

$$\mbox{Pr}(a < x < b) = \int_a^b \frac{1}{\sqrt{2\pi}s} \exp\left\{-\frac{1}{2}\left( \frac{x-m}{s} \right)^2\right\} \, dx$$

## Standardized units ctnd

- If we convert the normally distributed data to standard units we can quickly know if, for example, a person is about average ($z=0$), one of the largest ($z=2$), one of the smallest ($z=-2$) or an extremely rare occurrence ($z>3$ or $z < -3$).
- Note that it does not matter what the original units are, these rules apply to data that is approximately normal.

## Standardized units ctnd

- In R we can obtain standard units using the function `scale`
```{r}
z <- scale(x)
```

## Standardized units ctnd

- Now to see how many men are within 2 SDs from the average we simply type:

```{r}
mean(abs(z) < 2)
```

- Note that it is about 95% which is what the normal distribution predicts!  
- To further confirm that in fact the approximation is a good one we can use quantile-quantile plots.



## Quantile-quantile QQ plots (new video)

- A systematic way to assess how well the normal distribution fits the data is to check if the observed and predicted proportions match. 
- In general, the approach of the QQ-plot is as follows

1. Define a series of proportions $p=0.05,\dots .95$
2. For each $p$ determine the value $q$ so that the proportion of values in the data below $q$ is $p$. The $q$s are referred to as the _quantiles_.

## Quantile-quantile QQ plots ctnd

- To give a quick a example, for the male heights data we have that
```{r}
mean(x <= 69.5)
```
- 50% are shorter or equal to 69 inches. This implies that if $p=0.50$ then $q=69.5$.

## Quantile-quantile QQ plots ctnd

- Now we define a series of $p$
```{r}
p <- seq(0.05, 0.95, 0.05)
```

- If the quantiles for the data match the quantiles for the normal then it must be because the data follows a normal distribution.

## Quantile-quantile QQ plots ctnd

- To obtain the quantiles from the data we can use the `quantile` function like this:
```{r}
observed_quantiles <- quantile(x, p)
```

## Quantile-quantile QQ plots ctnd

- To obtain the theoretical normal distribution quantiles, with the corresponding average and SD,  we use the `qnorm` function:
```{r}
theoretical_quantiles <- qnorm( p, mean = mean(x), sd = sd(x))
```

## Quantile-quantile QQ plots ctnd

- To see if the match or not we plot them against each other and draw the identity line:

```{r}
plot(theoretical_quantiles, observed_quantiles)
abline(0,1)
```

## Quantile-quantile QQ plots with standard units

- Note that this code become much cleaner if we use standard units:
```{r}
observed_quantiles <- quantile(z, p)
theoretical_quantiles <- qnorm(p) 
plot(theoretical_quantiles, observed_quantiles)
abline(0,1)
```

- Note that qqplots are useful to compare to other distributions, not just the normal


## Summarizing male heights with two numbers 

- Using the histogram, density plots and qq-plots we have become convinced that the male height data is well approximated with a normal distribution. 
- In this case, we report back to ET a very succinct summary: Male heights follow a normal distribution with an average of `r average` inches and a SD of `r SD` inches. 
- With this information ET will have everything he needs to know what to expect when he meets our male students.


## Percentiles (new very short video)

- Before we move on, let's define some terms that are commonly used in exploratory data analysis.

- _Percentiles_ are special case of  _quantiles_ that are commonly used. The percentiles are the quantiles you obtain when setting the $p$ at $0.01, 0.02, ..., 0.99$. 
- We call, for example, the case of $p=0.25$ the 25-th percentile, which gives us a number for which 25% of the data is below. 
- The most famous percentile is the 50th also known as the _median_. 

## Percentiles

- Note that for the normal distribution the _median_ and average are the same, but this is generally not the case.

- Another special case that receives a name are the _quartiles_ which are obtained when setting $p=0.25,0.50$, and $0.75$. 


## Boxplots (new video)

- To introduce boxplots we will go back to the US murders data. 
- Suppose want to summarize the murder rate distribution.

## Boxplots ctnd

- Using the data visualization technique we have learned we  notice that the normal approximation does not apply here:
```{r, echo=FALSE}
data(murders)
murders <- murders %>% mutate(rate = total/population*100000)
library(gridExtra)
p1 <- murders %>% ggplot(aes(x=rate)) + geom_histogram(binwidth = 1) + ggtitle("Histogram")
p2 <- murders %>% ggplot(aes(sample=rate)) + 
  geom_qq(dparams=summarize(murders, mean=mean(rate), sd=sd(rate))) +
  geom_abline() + ggtitle("QQ-plot")
grid.arrange(p1, p2, ncol = 2)
```

- In this case, the histogram, or a smooth density plot, would serve as a relatively succinct summary. 

## Boxplots ctnd


- Now, suppose those used to receiving just two numbers as summaries ask us for a more compact summary.

- Here Tukey offers some advice. 
- Provide a five number summary composed of the range along with the quartiles (the 25th, 50th, and 75th percentiles). 
- Tukey further suggested that we ignore _outliers_ when computing the range and instead plot these as independent points. 
- We provide a detailed explanation of outliers later in the chapter. 
- Finally, he suggested we plot these numbers as a "box" with "whiskers"" like this:
 

## Boxplots ctnd

- Here is the boxplot for the murder rate
```{r, echo=FALSE}
murders %>% ggplot(aes("",rate)) + geom_boxplot() +
  coord_cartesian(xlim = c(0, 2)) + xlab("")
```

## Boxplots ctnd

- with the box defined by the 25% and 75% percentile and the whiskers showing the range. 
- The distance between these two are called the _interquartile_ range. - 
The two points are outliers according to Tukey's definition. The median is shown with a horizontal line.  
- Today, we call these _boxplots_.

## Boxplots ctnd

- From just this simple  plot we know that the median is about 2.5, that the distribution is not symmetric, and that the range is 0 to 5 for the great majority of states with two exceptions.

## Boxplots to compare

- Boxplots  are even more useful when we want to quickly compare two or more distributions. 
- For example, here are the heights for men and women.

```{r, echo=FALSE}
heights %>% ggplot(aes(x=sex, y=height, fill=sex)) +
  geom_boxplot()
```

## Boxplots to compare ctnd

- The plot immediately reveals that males are, on average, taller than females. 
- The standard deviations appear to be similar. 


## Are women heights normally distributed? (new video)
 
- Note we have to give ET a full summary of our heights as we have not yet summarized female heights. 
- We expect that they will follow a normal distribution, just like males. 

## Are women heights normally distributed? ctnd

- However, exploratory plots reveal that the approximation is not as useful:
 

```{r, echo=FALSE}
p1 <- heights %>% filter(sex=="Female") %>%
  ggplot(aes(height)) +
  geom_density(fill="#F8766D") 
p2 <- heights %>% filter(sex=="Female") %>% 
  ggplot(aes(sample=scale(height))) +
  geom_qq() + geom_abline() + ylab("Standard Units")
grid.arrange(p1, p2, ncol=2)
```

## Are women heights normally distributed? ctnd

- We see something we did not see for the males. 
- The density plot has a second "bump". 
- Also the qqplot shows that the highest points, tend to be taller than expected by the normal distribution. 
- When reporting back to ET we might need to provide a histogram  rather than just the average and standard deviation for the female heights. 

## Are women heights normally distributed? ctnd

- We have noticed what didn't expected to see. (remind us of Tukey's quote) 

>> The greatest value of a picture is when it forces us to notice what we never expected to see.

## Are women heights normally distributed? ctnd

- If we look at other female height distributions we do find that they are well approximated with a normal distribution. 


```{r, echo=FALSE}
p1 
```

## Are women heights normally distributed? ctnd

- How are our female students?
- Is our class a requirement for the female basketball team? Are small proportion of females claiming to be taller than they are? - Another, perhaps more likely explanation, is that in the form students used to entire their heights, `FEMALE` was the default sex and some males entered their heights but forgot to change the sex variable. 
- In any case, data visualization has helped discover a potential flaw in our data. 


